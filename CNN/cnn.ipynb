{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2XQqDsxWzqZiaOCpnqlzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdul3909/Deep-Learning/blob/main/CNN/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVTAoWBGKsEg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1w7X1CHGkpLs",
        "outputId": "5e0798a3-1f63-4db6-b13e-f59e42b09a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extracting dataset from zip file"
      ],
      "metadata": {
        "id": "baKtthhBbe8U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = './dataset.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RxGlL9D9SIC",
        "outputId": "c5db94f1-a845-49b9-fc91-940c8f9d98ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preprocessing\n",
        "### Preprocessing the raining set"
      ],
      "metadata": {
        "id": "70oay96jb0OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "training_set = train_data.flow_from_directory(\n",
        "    'dataset/training_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")"
      ],
      "metadata": {
        "id": "5xqbOq_9krFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f99d4029-d1d1-4a07-cb0d-a98b7952fec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing the test set"
      ],
      "metadata": {
        "id": "u4Oymtv_fiE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "\n",
        "test_set = test_data.flow_from_directory(\n",
        "    'dataset/test_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\"\n",
        ")"
      ],
      "metadata": {
        "id": "oILd1ooTn5I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91782a91-b089-405d-ef7e-e7814a06226a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KC8Y93os579Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Building the CNN\n",
        "\n",
        "### Initializing the CNN"
      ],
      "metadata": {
        "id": "HxKo6DEdfq3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = tf.keras.Sequential()"
      ],
      "metadata": {
        "id": "t-8Y2OQzSzIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Convolution"
      ],
      "metadata": {
        "id": "hseaw3iFgCAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ],
      "metadata": {
        "id": "YdvgZbU-gEr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Pooling"
      ],
      "metadata": {
        "id": "2eaNbHOng9Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "2sYlsrNtg_Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding a second convolutional layer"
      ],
      "metadata": {
        "id": "Y0HrLodUiPGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ],
      "metadata": {
        "id": "MbpuCzxtiXOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Flattening"
      ],
      "metadata": {
        "id": "tHpRjnnoirL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "metadata": {
        "id": "tb3mjvJiiN73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Full connection"
      ],
      "metadata": {
        "id": "aIbFRWCSi3Gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu', ))"
      ],
      "metadata": {
        "id": "gt5seF8ii0eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Output layer"
      ],
      "metadata": {
        "id": "QgWozW2OjQOn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) "
      ],
      "metadata": {
        "id": "gK_-qUewjR0Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the CNN\n",
        "### Compiling the CNN"
      ],
      "metadata": {
        "id": "lpZ3cqoBqrk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cjikcBn8q1Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the CNN on the training set and evaluating it on the test set"
      ],
      "metadata": {
        "id": "ibXh8weZrJhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit(x = training_set, validation_data=test_set, epochs=28)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7kNaiierZVg",
        "outputId": "a43ef686-4504-4a8f-f937-970c5344353e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/28\n",
            "250/250 [==============================] - 69s 272ms/step - loss: 0.6701 - accuracy: 0.5871 - val_loss: 0.6720 - val_accuracy: 0.6130\n",
            "Epoch 2/28\n",
            "250/250 [==============================] - 68s 271ms/step - loss: 0.6236 - accuracy: 0.6529 - val_loss: 0.6154 - val_accuracy: 0.6750\n",
            "Epoch 3/28\n",
            "250/250 [==============================] - 68s 272ms/step - loss: 0.5719 - accuracy: 0.7042 - val_loss: 0.5446 - val_accuracy: 0.7410\n",
            "Epoch 4/28\n",
            "250/250 [==============================] - 69s 274ms/step - loss: 0.5295 - accuracy: 0.7385 - val_loss: 0.5102 - val_accuracy: 0.7555\n",
            "Epoch 5/28\n",
            "250/250 [==============================] - 68s 271ms/step - loss: 0.5076 - accuracy: 0.7487 - val_loss: 0.4891 - val_accuracy: 0.7720\n",
            "Epoch 6/28\n",
            "250/250 [==============================] - 68s 272ms/step - loss: 0.4813 - accuracy: 0.7678 - val_loss: 0.4899 - val_accuracy: 0.7685\n",
            "Epoch 7/28\n",
            "250/250 [==============================] - 68s 273ms/step - loss: 0.4684 - accuracy: 0.7766 - val_loss: 0.4912 - val_accuracy: 0.7665\n",
            "Epoch 8/28\n",
            "250/250 [==============================] - 68s 273ms/step - loss: 0.4524 - accuracy: 0.7826 - val_loss: 0.4751 - val_accuracy: 0.7835\n",
            "Epoch 9/28\n",
            "250/250 [==============================] - 67s 270ms/step - loss: 0.4450 - accuracy: 0.7914 - val_loss: 0.4899 - val_accuracy: 0.7650\n",
            "Epoch 10/28\n",
            "250/250 [==============================] - 68s 271ms/step - loss: 0.4274 - accuracy: 0.7944 - val_loss: 0.5055 - val_accuracy: 0.7540\n",
            "Epoch 11/28\n",
            "250/250 [==============================] - 68s 272ms/step - loss: 0.4212 - accuracy: 0.8029 - val_loss: 0.4833 - val_accuracy: 0.7815\n",
            "Epoch 12/28\n",
            "250/250 [==============================] - 67s 269ms/step - loss: 0.4071 - accuracy: 0.8099 - val_loss: 0.4550 - val_accuracy: 0.7965\n",
            "Epoch 13/28\n",
            "250/250 [==============================] - 67s 267ms/step - loss: 0.3829 - accuracy: 0.8265 - val_loss: 0.4661 - val_accuracy: 0.7865\n",
            "Epoch 14/28\n",
            "250/250 [==============================] - 67s 267ms/step - loss: 0.3864 - accuracy: 0.8235 - val_loss: 0.4695 - val_accuracy: 0.7910\n",
            "Epoch 15/28\n",
            "250/250 [==============================] - 67s 268ms/step - loss: 0.3759 - accuracy: 0.8309 - val_loss: 0.4772 - val_accuracy: 0.7875\n",
            "Epoch 16/28\n",
            "250/250 [==============================] - 67s 268ms/step - loss: 0.3605 - accuracy: 0.8369 - val_loss: 0.4741 - val_accuracy: 0.7995\n",
            "Epoch 17/28\n",
            "250/250 [==============================] - 67s 267ms/step - loss: 0.3510 - accuracy: 0.8446 - val_loss: 0.4794 - val_accuracy: 0.7960\n",
            "Epoch 18/28\n",
            "250/250 [==============================] - 67s 267ms/step - loss: 0.3242 - accuracy: 0.8565 - val_loss: 0.5507 - val_accuracy: 0.7605\n",
            "Epoch 19/28\n",
            "250/250 [==============================] - 67s 269ms/step - loss: 0.3280 - accuracy: 0.8520 - val_loss: 0.4730 - val_accuracy: 0.7970\n",
            "Epoch 20/28\n",
            "250/250 [==============================] - 67s 269ms/step - loss: 0.3045 - accuracy: 0.8670 - val_loss: 0.4960 - val_accuracy: 0.7895\n",
            "Epoch 21/28\n",
            "250/250 [==============================] - 68s 272ms/step - loss: 0.3019 - accuracy: 0.8699 - val_loss: 0.4939 - val_accuracy: 0.7895\n",
            "Epoch 22/28\n",
            "250/250 [==============================] - 70s 278ms/step - loss: 0.2823 - accuracy: 0.8765 - val_loss: 0.4912 - val_accuracy: 0.7950\n",
            "Epoch 23/28\n",
            "250/250 [==============================] - 68s 272ms/step - loss: 0.2856 - accuracy: 0.8777 - val_loss: 0.4971 - val_accuracy: 0.7950\n",
            "Epoch 24/28\n",
            "250/250 [==============================] - 67s 269ms/step - loss: 0.2666 - accuracy: 0.8841 - val_loss: 0.5014 - val_accuracy: 0.8105\n",
            "Epoch 25/28\n",
            "250/250 [==============================] - 68s 270ms/step - loss: 0.2645 - accuracy: 0.8861 - val_loss: 0.5236 - val_accuracy: 0.7980\n",
            "Epoch 26/28\n",
            "250/250 [==============================] - 68s 270ms/step - loss: 0.2435 - accuracy: 0.8985 - val_loss: 0.6186 - val_accuracy: 0.7655\n",
            "Epoch 27/28\n",
            "250/250 [==============================] - 68s 270ms/step - loss: 0.2334 - accuracy: 0.9021 - val_loss: 0.5341 - val_accuracy: 0.7945\n",
            "Epoch 28/28\n",
            "250/250 [==============================] - 67s 267ms/step - loss: 0.2214 - accuracy: 0.9116 - val_loss: 0.5957 - val_accuracy: 0.7910\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0b151e58d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making a single prediction"
      ],
      "metadata": {
        "id": "RGEqgWFRwMDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_img = image.load_img('dataset/single_prediction/cat1.jpg', target_size=(64, 64))\n",
        "test_img = image.img_to_array(test_img)\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "result = cnn.predict(test_img/255.0)\n",
        "if result[0][0] > 0.5:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'"
      ],
      "metadata": {
        "id": "8SglIJ3YwGIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lq3pbAqFDUjG",
        "outputId": "1f001de5-f9d8-4990-bea6-781847ed6201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPa-nXlJDF5b",
        "outputId": "0f9b2af0-dd72-4072-f617-2a89a5efd7fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cats': 0, 'dogs': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}